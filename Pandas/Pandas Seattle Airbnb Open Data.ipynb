{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d41e95",
   "metadata": {},
   "source": [
    "Finding Missing Values\n",
    "\n",
    "https://medium.com/analytics-vidhya/python-finding-missing-values-in-a-data-frame-3030aaf0e4fd\n",
    "\n",
    "Handling Missing Values in a Data Frame\n",
    "\n",
    "\n",
    "https://medium.com/analytics-vidhya/python-handling-missing-values-in-a-data-frame-4156dac4399"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f93ee",
   "metadata": {},
   "source": [
    "## Seattle Airbnb Open Data\n",
    "\n",
    "https://www.kaggle.com/datasets/airbnb/seattle?resource=download&select=reviews.csv\n",
    "\n",
    "####  Context\n",
    "Since 2008, guests and hosts have used Airbnb to travel in a more unique, personalized way. As part of the Airbnb Inside initiative, this dataset describes the listing activity of homestays in Seattle, WA.\n",
    "\n",
    "#### Content\n",
    "The following Airbnb activity is included in this Seattle dataset:\n",
    "\n",
    "Listings, including full descriptions and average review score\n",
    "\n",
    "Reviews, including unique id for each reviewer and detailed comments\n",
    "\n",
    "Calendar, including listing id and the price and availability for that day\n",
    "#### Inspiration\n",
    "Can you describe the vibe of each Seattle neighborhood using listing descriptions?\n",
    "What are the busiest times of the year to visit Seattle? By how much do prices spike?\n",
    "Is there a general upward trend of both new Airbnb listings and total Airbnb visitors to Seattle?\n",
    "\n",
    "http://insideairbnb.com/get-the-data/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "579e345b",
   "metadata": {},
   "source": [
    "### Finding Missing Values in a Pandas Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59523542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "266ba40b",
   "metadata": {},
   "source": [
    "Step 1: Load the data frame and study the structure of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd10282",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'listings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_listing \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mlistings.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m display(df_listing\u001b[39m.\u001b[39mdescribe())\n\u001b[0;32m      3\u001b[0m display(df_listing\u001b[39m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\awedo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\awedo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\awedo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\awedo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\awedo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\awedo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\awedo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'listings.csv'"
     ]
    }
   ],
   "source": [
    "df_listing = pd.read_csv(\"listings.csv\")\n",
    "display(df_listing.describe())\n",
    "display(df_listing.head())\n",
    "display(df_listing.dtypes.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fe490fe",
   "metadata": {},
   "source": [
    "Step 2: Separate categorical and numerical columns in the data frame\n",
    "- False = numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab0ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listing.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e87f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listing.dtypes == 'object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8011019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separated the original data frame into 2 groups and assigned them new variable\n",
    "numerical_value = df_listing.columns[df_listing.dtypes != 'object']\n",
    "categorical_value = df_listing.columns[df_listing.dtypes == 'object']\n",
    "\n",
    "print(numerical_value)\n",
    "print(categorical_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c0a63d0",
   "metadata": {},
   "source": [
    "Step 3: Find the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only Prints out the column in the numerical_value which consists of all the columns in the data frame which are not object data type\n",
    "df_listing[numerical_value]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f88f2ae",
   "metadata": {},
   "source": [
    "- True = missing values\n",
    "- False = does not have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isnull() to find out all the fields which have the missing values\n",
    "df_listing[numerical_value].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum/count of all missing values in each column\n",
    "df_listing[numerical_value].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b08f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting out the columns in descending order to have a better picture\n",
    "df_listing[numerical_value].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de037648",
   "metadata": {},
   "source": [
    "To get % of missing values in each column you can divide by length of the data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ea5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives you the number of rows in the data frame\n",
    "len(df_listing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a063648",
   "metadata": {},
   "source": [
    "As you can see below license column is missing 100% of the data and square_feet column is missing 97% of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a709c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listing[numerical_value].isnull().sum().sort_values(ascending=False)/len(df_listing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6177dfab",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "1. Use isnull() function to identify the missing values in the data frame\n",
    "2. Use sum() functions to get sum of all missing values per column\n",
    "3. use sort_values(ascending=False) function to get columns with the missing values in descending order\n",
    "4. Divide by len(df) to get % of missing values in each column\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "206c34b1",
   "metadata": {},
   "source": [
    "### Handling Missing Values in a Data Frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cff45674",
   "metadata": {},
   "source": [
    "1. Deleting all rows/columns with missing data:This can be used when you have rows/columns where majority of the data is missing. When you are deleting rows/columns you might be losing some valuable information and lead to biased models. So analyze your data before deleting and check if there is any particular reason for missing data.\n",
    "\n",
    "2. Imputing data: This is by far the most common way used to handle missing data. In this method you impute a value where data is missing. Imputing data can introduce bias into the datasets. Imputation can be done multiple ways.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of missing data on each numerical column\n",
    "df_listing[numerical_value].isnull().sum().sort_values(ascending=False)/len(df_listing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ade2eec2",
   "metadata": {},
   "source": [
    "- 100% of the values in license column and 97% of the square_feet column are missing data in numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5dda65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of missing data on each categorical column\n",
    "df_listing[categorical_value].isnull().sum().sort_values(ascending=False)/len(df_listing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2001d7e",
   "metadata": {},
   "source": [
    "- 60% of the values in monthly_price, 51% of values in security_deposit and 47% of values in weekly_price are missing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bcb3824",
   "metadata": {},
   "source": [
    "### 1. Deleting rows/columns with missing data:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0195c4bd",
   "metadata": {},
   "source": [
    "axis =1 represents column, axis=0 represent rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the drop method\n",
    "df = df_listing.drop(columns=[\"license\",\"square_feet\",\"monthly_price\",\"security_deposit\",\"weekly_price\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f003ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separated the new data frame [df] into 2 groups and assigned them new variable\n",
    "\n",
    "numerical_value_1 = df.columns[df.dtypes != 'object']\n",
    "categorical_value_1 = df.columns[df.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa46721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of missing data on each numerical column for the new df data after dropping\n",
    "df[numerical_value_1].isnull().sum().sort_values(ascending=False)/len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe7e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of missing data on each categorical column for the new df data after dropping\n",
    "df[categorical_value_1].isnull().sum().sort_values(ascending=False)/len(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e154b668",
   "metadata": {},
   "source": [
    "#### Deleting rows/columns with NA\n",
    "- 'any' -->  even if one value has NA in row or column it will delete those columns. \n",
    "-  “all” only if all the values in rows/columns have NA deletion will happen.\n",
    "- If 0 then drops rows with NA values, if 1 then drops columns with NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete row with NA in host_name column\n",
    "df = df.dropna(subset=['host_name'],how='any',axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73844fb3",
   "metadata": {},
   "source": [
    "### 2. Imputing Data\n",
    "- imputing mean, median or mode of the column in place of the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8418c3a",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb2b770d",
   "metadata": {},
   "source": [
    "Filling catagorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9991e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listing[categorical_value].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0230da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df_listing[categorical_value].fillna(\"Missing_Data\")\n",
    "missing.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdf37597",
   "metadata": {},
   "source": [
    "Filling numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listing[numerical_value].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0576b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mean = df_listing[numerical_value].fillna(np.mean)\n",
    "fill_mean.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3dad026",
   "metadata": {},
   "source": [
    "Using lambda x: x.fillna(x.mean()),axis=0 to calculate mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7268ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mean = df_listing[numerical_value].apply(lambda x: x.fillna(x.mean()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43876149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fill missing values with mean for numerical col\n",
    "fill_mean= lambda x: x.fillna(x.mean())\n",
    "\n",
    "# apply finction to fill the missing values\n",
    "df_listing[numerical_value] = df_listing[numerical_value].apply(fill_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72291361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listing.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "acd2ce6c7faff7b1a0bc37552e4fafa8b9624856f11cac0dc7e108d2381226fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
